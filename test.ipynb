{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import os\n",
    "import langchain\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "os.environ['PINECONE_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(directory):\n",
    "    file_loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = read_doc('documents/')\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the document into chunks\n",
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = chunk_data(docs=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000001FEE3FE8D30>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000001FEE3AFAA90>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Embedding Technique of OpenAI\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embeddings.embed_query(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])\n",
    "\n",
    "index_name = \"langchainvectors\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langchainvectors'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector search DB in Pinecone\n",
    "## Create vector DB in Pinecone\n",
    "\n",
    "# index_name = \"langchain-index\"\n",
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "        docs,\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity retrival from vector DB\n",
    "\n",
    "def retrieve_query(query,k=2):\n",
    "    matching_results = vectorstore_from_docs.similarity_search(query,k=2)\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct',temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm,chain_type='stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search answers from vector DB\n",
    "\n",
    "def retrieve_answers(query):\n",
    "    doc_search = retrieve_query(query)\n",
    "    print(doc_search)\n",
    "    response = chain.run(input_documents=doc_search,question=query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='11.8 crore farmers, including marginal and small farmers.  Crop \\ninsurance is given to  4 crore farmers under PM Fasal Bima \\nYojana. These, besides several other programmes, are assisting \\n‘Annadata’  in producing food for the country and the world.  \\n15. Electroni c National Agriculture Market has integrated  \\n1361 mandis, and is providing services to 1.8 crore farmers with \\ntrading volume of ` 3 lakh crore.  \\n16. The sector is poised for inclusive, balanced, higher growth \\nand productivity. These are facilitated from farme r-centric \\npolicies, income support, coverage of risks through price and', metadata={'page': 8.0, 'source': 'documents\\\\budget_speech.pdf'}), Document(page_content='16 \\n doubled.  Implementation of Pradhan Mantri Matsya Sampada \\nYojana (PMMSY) will be stepped up to:  \\n(1) enhance aquaculture productivity from existing 3 to  \\n5 tons per hectare,  \\n(2) double exports to ` 1 lakh crore and  \\n(3) generate  55 lakh employment opportunities in near \\nfuture.  \\nFive integrated aquaparks will be setup.  \\nLakhpati Didi  \\n56. Eighty -three lakh SHGs  with nine crore women are \\ntransforming rural socio -economic landscape with \\nempowerment and self -reliance. Their success has as sisted \\nnearly one crore women to become Lakhpati Didi already. They \\nare an inspiration to others. Their achievements will be \\nrecognized through honouring them. Buoyed by the success, it \\nhas been decided to enhance the target for Lakhpati Didi from  \\n2 crore to 3 crore.', metadata={'page': 19.0, 'source': 'documents\\\\budget_speech.pdf'})]\n",
      " The agriculture target will be increased by one crore.\n"
     ]
    }
   ],
   "source": [
    "answer = retrieve_answers('How much the agriculture target will be increased by how many crores?')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
